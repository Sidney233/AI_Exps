{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验2 运用CNN进行MNIST手写数字识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验是经典的MNIST手写数字识别，要求使用CNN来实现。因为我修过这方面的专业选修课，所以准备使用我以前用过的AlexNet来进行分类。AlexNet使用pytorch来搭建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用pytorch官方的API读取数据\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# 查看使用硬件\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using \"+ str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet通过5层卷积核提取出图片特征，最后用一个简单的前馈神经网络的分类器用于最后的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (feature_extraction): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义卷积神经网络\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=256 * 3 * 3, out_features=1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.feature_extraction(inputs)\n",
    "        inputs = inputs.view(-1, 256 * 3 * 3)\n",
    "        inputs = self.classifier(inputs)\n",
    "        return F.log_softmax(inputs, dim=1)\n",
    "\n",
    "\n",
    "model = AlexNet()\n",
    "print(model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化算法\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数和测试函数\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.299282  [    0/60000]\n",
      "loss: 2.301512  [10000/60000]\n",
      "loss: 2.299158  [20000/60000]\n",
      "loss: 2.302033  [30000/60000]\n",
      "loss: 2.286094  [40000/60000]\n",
      "loss: 2.138496  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.005829 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.587896  [    0/60000]\n",
      "loss: 0.351457  [10000/60000]\n",
      "loss: 0.339950  [20000/60000]\n",
      "loss: 0.146083  [30000/60000]\n",
      "loss: 0.105740  [40000/60000]\n",
      "loss: 0.033158  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.001320 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.059357  [    0/60000]\n",
      "loss: 0.095500  [10000/60000]\n",
      "loss: 0.092435  [20000/60000]\n",
      "loss: 0.024516  [30000/60000]\n",
      "loss: 0.043396  [40000/60000]\n",
      "loss: 0.024010  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.000489 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.025964  [    0/60000]\n",
      "loss: 0.068566  [10000/60000]\n",
      "loss: 0.074376  [20000/60000]\n",
      "loss: 0.018576  [30000/60000]\n",
      "loss: 0.022572  [40000/60000]\n",
      "loss: 0.020007  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.000409 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.015538  [    0/60000]\n",
      "loss: 0.023682  [10000/60000]\n",
      "loss: 0.059468  [20000/60000]\n",
      "loss: 0.016453  [30000/60000]\n",
      "loss: 0.018882  [40000/60000]\n",
      "loss: 0.015459  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.000363 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.012747  [    0/60000]\n",
      "loss: 0.023638  [10000/60000]\n",
      "loss: 0.035035  [20000/60000]\n",
      "loss: 0.009936  [30000/60000]\n",
      "loss: 0.015075  [40000/60000]\n",
      "loss: 0.005887  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.000338 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.015852  [    0/60000]\n",
      "loss: 0.020476  [10000/60000]\n",
      "loss: 0.032302  [20000/60000]\n",
      "loss: 0.009335  [30000/60000]\n",
      "loss: 0.014866  [40000/60000]\n",
      "loss: 0.006793  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.000346 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.002798  [    0/60000]\n",
      "loss: 0.012568  [10000/60000]\n",
      "loss: 0.011175  [20000/60000]\n",
      "loss: 0.014188  [30000/60000]\n",
      "loss: 0.003473  [40000/60000]\n",
      "loss: 0.010566  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.000390 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.002301  [    0/60000]\n",
      "loss: 0.014833  [10000/60000]\n",
      "loss: 0.007527  [20000/60000]\n",
      "loss: 0.008498  [30000/60000]\n",
      "loss: 0.004174  [40000/60000]\n",
      "loss: 0.004580  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.000332 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.000694  [    0/60000]\n",
      "loss: 0.011855  [10000/60000]\n",
      "loss: 0.006730  [20000/60000]\n",
      "loss: 0.002288  [30000/60000]\n",
      "loss: 0.001224  [40000/60000]\n",
      "loss: 0.004275  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.000307 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.026612  [    0/60000]\n",
      "loss: 0.011229  [10000/60000]\n",
      "loss: 0.023395  [20000/60000]\n",
      "loss: 0.002803  [30000/60000]\n",
      "loss: 0.000960  [40000/60000]\n",
      "loss: 0.001273  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.000378 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.002619  [    0/60000]\n",
      "loss: 0.018715  [10000/60000]\n",
      "loss: 0.005058  [20000/60000]\n",
      "loss: 0.026334  [30000/60000]\n",
      "loss: 0.001011  [40000/60000]\n",
      "loss: 0.000465  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.000417 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000246  [    0/60000]\n",
      "loss: 0.006586  [10000/60000]\n",
      "loss: 0.034858  [20000/60000]\n",
      "loss: 0.001104  [30000/60000]\n",
      "loss: 0.000325  [40000/60000]\n",
      "loss: 0.001485  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000297 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000119  [    0/60000]\n",
      "loss: 0.007845  [10000/60000]\n",
      "loss: 0.002472  [20000/60000]\n",
      "loss: 0.001170  [30000/60000]\n",
      "loss: 0.001023  [40000/60000]\n",
      "loss: 0.067125  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000333 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000805  [    0/60000]\n",
      "loss: 0.007736  [10000/60000]\n",
      "loss: 0.009138  [20000/60000]\n",
      "loss: 0.003119  [30000/60000]\n",
      "loss: 0.000158  [40000/60000]\n",
      "loss: 0.001173  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.000442 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.000067  [    0/60000]\n",
      "loss: 0.031315  [10000/60000]\n",
      "loss: 0.006780  [20000/60000]\n",
      "loss: 0.001235  [30000/60000]\n",
      "loss: 0.000129  [40000/60000]\n",
      "loss: 0.003685  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.000511 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.005012  [    0/60000]\n",
      "loss: 0.004625  [10000/60000]\n",
      "loss: 0.036248  [20000/60000]\n",
      "loss: 0.001236  [30000/60000]\n",
      "loss: 0.000530  [40000/60000]\n",
      "loss: 0.002952  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.000545 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.005506  [    0/60000]\n",
      "loss: 0.005121  [10000/60000]\n",
      "loss: 0.005818  [20000/60000]\n",
      "loss: 0.000730  [30000/60000]\n",
      "loss: 0.000278  [40000/60000]\n",
      "loss: 0.000177  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000361 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000733  [    0/60000]\n",
      "loss: 0.008309  [10000/60000]\n",
      "loss: 0.000984  [20000/60000]\n",
      "loss: 0.000272  [30000/60000]\n",
      "loss: 0.000023  [40000/60000]\n",
      "loss: 0.000641  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000379 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000620  [    0/60000]\n",
      "loss: 0.001336  [10000/60000]\n",
      "loss: 0.006503  [20000/60000]\n",
      "loss: 0.000251  [30000/60000]\n",
      "loss: 0.004714  [40000/60000]\n",
      "loss: 0.000683  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.000435 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.000175  [    0/60000]\n",
      "loss: 0.005071  [10000/60000]\n",
      "loss: 0.004786  [20000/60000]\n",
      "loss: 0.009185  [30000/60000]\n",
      "loss: 0.000081  [40000/60000]\n",
      "loss: 0.000109  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.000420 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.001946  [    0/60000]\n",
      "loss: 0.013228  [10000/60000]\n",
      "loss: 0.002112  [20000/60000]\n",
      "loss: 0.001642  [30000/60000]\n",
      "loss: 0.000057  [40000/60000]\n",
      "loss: 0.000043  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.000486 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.000050  [    0/60000]\n",
      "loss: 0.001158  [10000/60000]\n",
      "loss: 0.000406  [20000/60000]\n",
      "loss: 0.002827  [30000/60000]\n",
      "loss: 0.000035  [40000/60000]\n",
      "loss: 0.001268  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000407 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.000028  [    0/60000]\n",
      "loss: 0.009143  [10000/60000]\n",
      "loss: 0.000320  [20000/60000]\n",
      "loss: 0.000136  [30000/60000]\n",
      "loss: 0.000019  [40000/60000]\n",
      "loss: 0.000206  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.000409 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000073  [    0/60000]\n",
      "loss: 0.001367  [10000/60000]\n",
      "loss: 0.000341  [20000/60000]\n",
      "loss: 0.000090  [30000/60000]\n",
      "loss: 0.000014  [40000/60000]\n",
      "loss: 0.000079  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.000374 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/60000]\n",
      "loss: 0.001437  [10000/60000]\n",
      "loss: 0.000091  [20000/60000]\n",
      "loss: 0.000005  [30000/60000]\n",
      "loss: 0.000010  [40000/60000]\n",
      "loss: 0.000152  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000396 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/60000]\n",
      "loss: 0.000802  [10000/60000]\n",
      "loss: 0.000147  [20000/60000]\n",
      "loss: 0.000021  [30000/60000]\n",
      "loss: 0.000005  [40000/60000]\n",
      "loss: 0.000007  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.000647 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/60000]\n",
      "loss: 0.006921  [10000/60000]\n",
      "loss: 0.018834  [20000/60000]\n",
      "loss: 0.000325  [30000/60000]\n",
      "loss: 0.000879  [40000/60000]\n",
      "loss: 0.000576  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000404 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000082  [    0/60000]\n",
      "loss: 0.002683  [10000/60000]\n",
      "loss: 0.000816  [20000/60000]\n",
      "loss: 0.002729  [30000/60000]\n",
      "loss: 0.000013  [40000/60000]\n",
      "loss: 0.000943  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.000436 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/60000]\n",
      "loss: 0.009652  [10000/60000]\n",
      "loss: 0.000865  [20000/60000]\n",
      "loss: 0.000076  [30000/60000]\n",
      "loss: 0.000293  [40000/60000]\n",
      "loss: 0.000026  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.000384 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 定义epoch数量并开始训练\n",
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到在10个epoch之后在测试集上的准确率就已经达到了99%，之后一直在99%浮动，最后稳定在99.3%，达到了这次作业的要求，如果要达到老师说的99.7%的准确率，可能要使用其他网络结构了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
